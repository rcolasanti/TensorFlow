{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"tmp/data/\", one_hot = True)\n",
    "\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfAnn(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden_1_layer = {'weights':[],'biases':[]}\n",
    "        self.hidden_2_layer = {'weights':[],'biases':[]}\n",
    "        self.hidden_3_layer = {'weights':[],'biases':[]}\n",
    "        self.output_layer = {'weights':[],'biases':[]}\n",
    "        self.np_hidden_1_layer={\"weights\":[],\"biases\":[]}\n",
    "        self.np_hidden_2_layer={\"weights\":[],\"biases\":[]}\n",
    "        self.np_hidden_3_layer={\"weights\":[],\"biases\":[]}\n",
    "        self.np_output_layer={\"weights\":[],\"biases\":[]}\n",
    "    \n",
    "    def init_empty(self,size,n_nodes_hl1,n_nodes_hl2,n_nodes_hl3,n_classes):\n",
    "        self.hidden_1_layer = {'weights':tf.Variable(tf.random_normal([size, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "        self.hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "        self.hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "        self.output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                        'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "    def init_values(self,size,l1_weights,l2_weights,l3_weights,out_weights,l1_biases,l2_biases,l3_biases,out_biases):\n",
    "        self.hidden_1_layer = {'weights':tf.Variable(l1_weights),'biases':tf.Variable(l1_biases)}\n",
    "        self.hidden_2_layer = {'weights':tf.Variable(l2_weights),'biases':tf.Variable(l2_biases)}\n",
    "        self.hidden_3_layer = {'weights':tf.Variable(l3_weights),'biases':tf.Variable(l3_biases)}\n",
    "        self.output_layer = {'weights':tf.Variable(out_weights),'biases':tf.Variable(out_biases)}\n",
    "\n",
    "\n",
    "    def create(self,data):\n",
    "        l1 = tf.add(tf.matmul(data,self.hidden_1_layer['weights']), self.hidden_1_layer['biases'])\n",
    "        l1 = tf.nn.relu(l1)\n",
    "\n",
    "        l2 = tf.add(tf.matmul(l1,self.hidden_2_layer['weights']), self.hidden_2_layer['biases'])\n",
    "        l2 = tf.nn.relu(l2)\n",
    "\n",
    "        l3 = tf.add(tf.matmul(l2,self.hidden_3_layer['weights']), self.hidden_3_layer['biases'])\n",
    "        l3 = tf.nn.relu(l3)\n",
    "\n",
    "        output =  tf.add(tf.matmul(l3,self.output_layer['weights']) , self.output_layer['biases'])\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def extract(self):\n",
    "        self.np_hidden_1_layer[\"weights\"] = neural_network_model.hidden_1_layer[\"weights\"].eval()\n",
    "        self.np_hidden_2_layer[\"weights\"] = neural_network_model.hidden_2_layer[\"weights\"].eval()\n",
    "        self.np_hidden_3_layer[\"weights\"] = neural_network_model.hidden_3_layer[\"weights\"].eval()\n",
    "        self.np_output_layer[\"weights\"] = neural_network_model.output_layer[\"weights\"].eval()\n",
    "        self.np_hidden_1_layer[\"biases\"] = neural_network_model.hidden_1_layer[\"biases\"].eval()\n",
    "        self.np_hidden_2_layer[\"biases\"] = neural_network_model.hidden_2_layer[\"biases\"].eval()\n",
    "        self.np_hidden_3_layer[\"biases\"] = neural_network_model.hidden_3_layer[\"biases\"].eval()\n",
    "        self.np_output_layer[\"biases\"] = neural_network_model.output_layer[\"biases\"].eval()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x,neural_network_model):\n",
    "    prediction = neural_network_model.create(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    hm_epochs = 10\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "        neural_network_model.extract()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss: 1665077.4106140137\n",
      "Epoch 1 completed out of 10 loss: 376538.92571258545\n",
      "Epoch 2 completed out of 10 loss: 207680.11528718472\n",
      "Epoch 3 completed out of 10 loss: 121175.00202047825\n",
      "Epoch 4 completed out of 10 loss: 73239.0776475668\n",
      "Epoch 5 completed out of 10 loss: 50062.821100176574\n",
      "Epoch 6 completed out of 10 loss: 32304.32735222578\n",
      "Epoch 7 completed out of 10 loss: 21913.27770452948\n",
      "Epoch 8 completed out of 10 loss: 18693.822882669418\n",
      "Epoch 9 completed out of 10 loss: 19557.44637697935\n",
      "Accuracy: 0.9473\n",
      "array([[ 0.36754656,  0.00396802, -1.0628358 , ..., -0.55542004,\n",
      "        -0.4289287 ,  2.0505106 ],\n",
      "       [-1.4701712 ,  0.19074635,  1.6281519 , ...,  0.57202315,\n",
      "        -1.7025607 ,  0.9469387 ],\n",
      "       [ 0.47146574, -1.20716   ,  2.2263017 , ..., -1.9913008 ,\n",
      "         0.279925  , -0.45598564],\n",
      "       ...,\n",
      "       [ 0.7813348 ,  0.03839272,  2.4179583 , ..., -1.0577943 ,\n",
      "         0.19103912, -1.0859323 ],\n",
      "       [ 2.2770443 ,  1.3218967 , -0.08537007, ..., -0.30515984,\n",
      "         0.31009853,  0.85519964],\n",
      "       [ 1.4297938 ,  1.1037115 , -1.0388628 , ...,  1.3276651 ,\n",
      "         0.45316637, -0.14810652]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "neural_network_model = TfAnn()\n",
    "neural_network_model.init_empty(784,n_nodes_hl1,n_nodes_hl2,n_nodes_hl3,n_classes)\n",
    "train_neural_network(x,neural_network_model)\n",
    "pprint(neural_network_model.np_hidden_1_layer[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_neural_network(x,neural_network_model):\n",
    "    prediction = neural_network_model.create(x)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        predictions = tf.argmax(prediction, 1)\n",
    "        correct = tf.equal(predictions, tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "        #con = tf.confusion_matrix(labels=y_, predictions=y )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473\n"
     ]
    }
   ],
   "source": [
    "test_neural_network_model = TfAnn()\n",
    "l1_weights = neural_network_model.np_hidden_1_layer[\"weights\"]\n",
    "l1_biases = neural_network_model.np_hidden_1_layer[\"biases\"]\n",
    "l2_weights = neural_network_model.np_hidden_2_layer[\"weights\"]\n",
    "l2_biases = neural_network_model.np_hidden_2_layer[\"biases\"]\n",
    "l3_weights = neural_network_model.np_hidden_3_layer[\"weights\"]\n",
    "l3_biases = neural_network_model.np_hidden_3_layer[\"biases\"]\n",
    "out_weights = neural_network_model.np_output_layer[\"weights\"]\n",
    "out_biases = neural_network_model.np_output_layer[\"biases\"]\n",
    "\n",
    "test_neural_network_model.init_values(784,l1_weights,l2_weights,l3_weights,out_weights,l1_biases,l2_biases,l3_biases,out_biases)\n",
    "run_neural_network(x,test_neural_network_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
