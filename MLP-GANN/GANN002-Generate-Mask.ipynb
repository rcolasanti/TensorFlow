{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from pprint import pprint\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "sess = tf.InteractiveSession()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfAnn(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden=[]\n",
    "        self.np_hidden=[]\n",
    "        \n",
    "        self.n_nodes=[]\n",
    "        self.n_classes = 0\n",
    "        self.n_hiden_layers = 0\n",
    "\n",
    "    # create empty network for training\n",
    "    def init_empty(self,layers,n_classes,size):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hiden_layers = len(layers)\n",
    "        for i in range(self.n_hiden_layers):\n",
    "            self.hidden.append({'weights':[],'biases':[]})\n",
    "            self.np_hidden.append({'weights':[],'biases':[]})\n",
    "            self.n_nodes.append(layers[i])\n",
    "        self.output_layer = {'weights':[],'biases':[]}\n",
    "        self.np_output_layer={\"weights\":[],\"biases\":[]}\n",
    "\n",
    "        for i in range(self.n_hiden_layers):\n",
    "            self.hidden[i] = {'weights':tf.Variable(tf.random_normal([size, self.n_nodes[i]])),\n",
    "                      'biases':tf.Variable(tf.random_normal([self.n_nodes[i]]))}\n",
    "            \n",
    "        self.output_layer = {'weights':tf.Variable(tf.random_normal([self.n_nodes[-1], self.n_classes])),\n",
    "                        'biases':tf.Variable(tf.random_normal([self.n_classes]))}\n",
    "\n",
    "    \n",
    "    def get_number_of_nodes(self,layer):\n",
    "        return len(self.hidden[layer]['weights'][0])\n",
    "    \n",
    "    # Reinflate network from json description\n",
    "    def init_json(self,jfile):\n",
    "        with open(jfile) as json_data:\n",
    "            tf_data = json.load(json_data)\n",
    "        self.n_classes = tf_data[\"n_classes\"]\n",
    "        self.n_hiden_layers = tf_data[\"n_hiden_layers\"]\n",
    "        self.hidden =tf_data[\"hidden\"]\n",
    "        \n",
    "        self.output_layer =tf_data[\"output\"]\n",
    "\n",
    "\n",
    "        \n",
    "    def create(self,data,mask):\n",
    "        # This is the heart of the ann where multiply the data by the wights to the layers \n",
    "        for i in range(self.n_hiden_layers):\n",
    "            project_weights = [list(np.array(a)*b) for a,b in zip(self.hidden[i]['weights'],mask[i])]\n",
    "            project_biases = [a*b for a,b in zip(self.hidden[i]['biases'],mask[i])]\n",
    "            layer = tf.add(\n",
    "                tf.matmul(data,project_weights)\n",
    "                , project_biases)\n",
    "            layer= tf.nn.relu(layer)\n",
    "        output =  tf.add(tf.matmul(layer,self.output_layer['weights']) , self.output_layer['biases'])\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    #Save a trained network as a json file\n",
    "    def extract(self,jfile):\n",
    "        for i in range(self.n_hiden_layers):\n",
    "            self.np_hidden[i][\"weights\"] = neural_network_model.hidden[i][\"weights\"].eval().tolist()\n",
    "            self.np_hidden[i][\"biases\"] = neural_network_model.hidden[i][\"biases\"].eval().tolist()\n",
    "        self.np_output_layer[\"weights\"] = neural_network_model.output_layer[\"weights\"].eval().tolist()\n",
    "        self.np_output_layer[\"biases\"] = neural_network_model.output_layer[\"biases\"].eval().tolist()\n",
    "        with open(jfile,\"w\") as jout:\n",
    "            json.dump({\"n_classes\":self.n_classes, # number of input classifier classes\n",
    "                       \"n_hiden_layers\":self.n_hiden_layers, # number of \n",
    "                       \"hidden\":self.np_hidden,# weights and biases\n",
    "                       # each layer is defined by dict {'weights':[],'biases':[]}\n",
    "                       \"output\":self.np_output_layer} # as for hidden\n",
    "                      ,jout)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "mask1=[1,2,3,4]\n",
    "mask2=[14,13,12,11]\n",
    "cross=randint(1,len(mask1))\n",
    "mask3=mask1[:cross]+mask2[cross:]\n",
    "print(mask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "x+=1\n",
    "print(x)\n",
    "x=x%2\n",
    "print(x)\n",
    "x+=1\n",
    "x=x%2\n",
    "print(x)\n",
    "x+=1\n",
    "x=x%2\n",
    "print(x)\n",
    "x+=1\n",
    "x=x%2\n",
    "print(x)\n",
    "x+=1\n",
    "x=x%2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gene(object):\n",
    "    size=0\n",
    "    mutation_rate=0.0\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mask=[0 for _ in range(Gene.size)]\n",
    "        self.fittness=0\n",
    "        \n",
    "    def random(self):\n",
    "        for i in range(Gene.size):\n",
    "            self.mask[i] = randint(0, 1)\n",
    "    \n",
    "    def cross(self,gene1):\n",
    "        cross_point = randint(1,Gene.size)\n",
    "        gene3 = Gene()\n",
    "        gene4 = Gene()\n",
    "        gene3.mask=gene1.mask[:cross]+self.mask[cross:]\n",
    "        gene4.mask=gene1.mask[cross:]+self.mask[:cross]\n",
    "        return gene3, gene4\n",
    "    \n",
    "    def mutate():\n",
    "        if ranom()<mutation_rate:\n",
    "            mut_point =  randint(0,Gene.size)\n",
    "            self.mask[mut_point]+=1\n",
    "            self.mask[mut_point]=self.mask[mut_point]%2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_neural_network(neural_network_model,mask,x_data_test,y_data_test):\n",
    "    # set up network\n",
    "    x = tf.placeholder('float')\n",
    "    prediction = neural_network_model.create(x,mask)    \n",
    "    \n",
    "    # ren test data\n",
    "    y_test_res=(sess.run(prediction,feed_dict={x:x_data_test}))       \n",
    "    # the correct data\n",
    "    true_class=np.argmax(y_data_test,1)\n",
    "    \n",
    "    # get the index of the outpt array with heighest value\n",
    "    predicted_class=np.argmax(y_test_res,1)\n",
    "    \n",
    "    # calculate confusion matix\n",
    "    cm = confusion_matrix(true_class,predicted_class)\n",
    "    cm = cm.astype('float')*10000 / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm = np.nan_to_num(cm, copy=True)\n",
    "    cm = cm.astype('int')\n",
    "    return accuracy_score(true_class, predicted_class) , cm*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676056338028169\n",
      "0.5211267605633803\n",
      "0.528169014084507\n",
      "0.49295774647887325\n",
      "0.4014084507042254\n",
      "0.5\n",
      "0.5774647887323944\n",
      "0.28169014084507044\n",
      "0.5985915492957746\n",
      "0.4647887323943662\n"
     ]
    }
   ],
   "source": [
    "with open(\"datasets/wine/wine_train.json\") as json_data:\n",
    "    test_dataset = json.load(json_data)\n",
    "\n",
    "test_x = np.asarray(test_dataset[\"attribs\"])\n",
    "test_y = np.asarray(test_dataset[\"target_hot\"])\n",
    "\n",
    "neural_network_model = TfAnn()\n",
    "neural_network_model.init_json(\"classifiers/wine-mlp.json\")\n",
    "Gene.size = neural_network_model.get_number_of_nodes(0)\n",
    "for _ in range(10):\n",
    "    a_gene = Gene()\n",
    "    a_gene.random()\n",
    "    acc,cf = test_neural_network(neural_network_model,[a_gene.mask],test_x,test_y)\n",
    "    pprint(acc)\n",
    "#plot_confusion_matrix(cf,[1,2,3],\"Cf matrix\",\"wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
