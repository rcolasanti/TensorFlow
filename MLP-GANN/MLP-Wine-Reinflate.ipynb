{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from pprint import pprint\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "sess = tf.InteractiveSession()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfAnn(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden=[]\n",
    "        self.np_hidden=[]\n",
    "        \n",
    "        self.n_nodes=[]\n",
    "        self.n_classes = 0\n",
    "        self.n_hiden_layers = 0\n",
    "\n",
    "    # create empty network for training\n",
    "    def init_empty(self,layers,n_classes,size):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hiden_layers = len(layers)\n",
    "        for i in range(self.n_hiden_layers):\n",
    "            self.hidden.append({'weights':[],'biases':[]})\n",
    "            self.np_hidden.append({'weights':[],'biases':[]})\n",
    "            self.n_nodes.append(layers[i])\n",
    "        self.output_layer = {'weights':[],'biases':[]}\n",
    "        self.np_output_layer={\"weights\":[],\"biases\":[]}\n",
    "\n",
    "        for i in range(self.n_hiden_layers):\n",
    "            self.hidden[i] = {'weights':tf.Variable(tf.random_normal([size, self.n_nodes[i]])),\n",
    "                      'biases':tf.Variable(tf.random_normal([self.n_nodes[i]]))}\n",
    "            \n",
    "        self.output_layer = {'weights':tf.Variable(tf.random_normal([self.n_nodes[-1], self.n_classes])),\n",
    "                        'biases':tf.Variable(tf.random_normal([self.n_classes]))}\n",
    "\n",
    "    \n",
    "    # Reinflate network from json description\n",
    "    def init_json(self,jfile):\n",
    "        with open(jfile) as json_data:\n",
    "            tf_data = json.load(json_data)\n",
    "        self.n_classes = tf_data[\"n_classes\"]\n",
    "        self.n_hiden_layers = tf_data[\"n_hiden_layers\"]\n",
    "        self.hidden =tf_data[\"hidden\"]\n",
    "        self.output_layer =tf_data[\"output\"]\n",
    "\n",
    "\n",
    "        \n",
    "    def create(self,data):\n",
    "        # This is the heart of the ann where multiply the data by the wights to the layers \n",
    "        for i in range(self.n_hiden_layers):\n",
    "            layer = tf.add(tf.matmul(data,self.hidden[i]['weights']), self.hidden[i]['biases'])\n",
    "            layer= tf.nn.relu(layer)\n",
    "        output =  tf.add(tf.matmul(layer,self.output_layer['weights']) , self.output_layer['biases'])\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    #Save a trained network as a json file\n",
    "    def extract(self,jfile):\n",
    "        for i in range(self.n_hiden_layers):\n",
    "            self.np_hidden[i][\"weights\"] = neural_network_model.hidden[i][\"weights\"].eval().tolist()\n",
    "            self.np_hidden[i][\"biases\"] = neural_network_model.hidden[i][\"biases\"].eval().tolist()\n",
    "        self.np_output_layer[\"weights\"] = neural_network_model.output_layer[\"weights\"].eval().tolist()\n",
    "        self.np_output_layer[\"biases\"] = neural_network_model.output_layer[\"biases\"].eval().tolist()\n",
    "        with open(jfile,\"w\") as jout:\n",
    "            json.dump({\"n_classes\":self.n_classes, # number of input classifier classes\n",
    "                       \"n_hiden_layers\":self.n_hiden_layers, # number of \n",
    "                       \"hidden\":self.np_hidden,# weights and biases\n",
    "                       # each layer is defined by dict {'weights':[],'biases':[]}\n",
    "                       \"output\":self.np_output_layer} # as for hidden\n",
    "                      ,jout)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_neural_network(neural_network_model,x_data_test,y_data_test):\n",
    "    # set up network\n",
    "    x = tf.placeholder('float')\n",
    "    prediction = neural_network_model.create(x)    \n",
    "    \n",
    "    # ren test data\n",
    "    y_test_res=(sess.run(prediction,feed_dict={x:x_data_test}))       \n",
    "    # the correct data\n",
    "    true_class=np.argmax(y_data_test,1)\n",
    "    \n",
    "    # get the index of the outpt array with heighest value\n",
    "    predicted_class=np.argmax(y_test_res,1)\n",
    "    \n",
    "    # calculate confusion matix\n",
    "    cm = confusion_matrix(predicted_class,true_class)\n",
    "    cm = cm.astype('float')*10000 / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm = np.nan_to_num(cm, copy=True)\n",
    "    cm = cm.astype('int')\n",
    "    print(accuracy_score(predicted_class,true_class))\n",
    "    return cm*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_confusion_matrix(cm, classes, title,classifier_name):\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    fig,ax= plt.subplots(figsize=(5,4))\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns_plot = sns.heatmap(cm, annot=True, ax = ax, cmap=\"Blues\"); #annot=True to annotate cells\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title(title); \n",
    "    ax.xaxis.set_ticklabels(classes); ax.yaxis.set_ticklabels(classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "array([[100.  ,   0.  ,   0.  ],\n",
      "       [  6.25,  87.5 ,   6.25],\n",
      "       [  0.  ,   0.  , 100.  ]])\n"
     ]
    }
   ],
   "source": [
    "with open(\"datasets/wine/wine_test.json\") as json_data:\n",
    "    test_dataset = json.load(json_data)\n",
    "\n",
    "test_x = np.asarray(test_dataset[\"attribs\"])\n",
    "test_y = np.asarray(test_dataset[\"target_hot\"])\n",
    "\n",
    "neural_network_model = TfAnn()\n",
    "neural_network_model.init_json(\"classifiers/wine-mlp.json\")\n",
    "cf = test_neural_network(neural_network_model,test_x,test_y)\n",
    "pprint(cf)\n",
    "#plot_confusion_matrix(cf,[1,2,3],\"Cf matrix\",\"wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
