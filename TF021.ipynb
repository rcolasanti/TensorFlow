{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pprint import pprint\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = np.genfromtxt(\"datasets/wine/wine_train_array.csv\", delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59210526, 0.17786561, 0.79569892, 0.25257732, 0.43478261,\n",
       "       0.55862069, 0.68823529, 0.42      , 0.29746835, 0.28327645,\n",
       "       0.49593496, 0.56981132, 0.48666128, 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine[:,:-3]\n",
    "Y = wine[:,-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59210526, 0.17786561, 0.79569892, 0.25257732, 0.43478261,\n",
       "       0.55862069, 0.68823529, 0.42      , 0.29746835, 0.28327645,\n",
       "       0.49593496, 0.56981132, 0.48666128])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x,train_y,test_x,test_y = create_feature_sets_and_labels('Data/pos.txt','Data/neg.txt')\n",
    "train_x = X\n",
    "train_y = Y\n",
    "n_nodes_hl1 = 5\n",
    "n_nodes_hl2 = 5\n",
    "\n",
    "n_classes = len(Y[0])\n",
    "hm_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfAnn(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden_1_layer = {'weights':[],'biases':[]}\n",
    "        self.hidden_2_layer = {'weights':[],'biases':[]}\n",
    "        self.output_layer = {'weights':[],'biases':[]}\n",
    "        self.np_hidden_1_layer={\"weights\":[],\"biases\":[]}\n",
    "        self.np_hidden_2_layer={\"weights\":[],\"biases\":[]}\n",
    "        self.np_output_layer={\"weights\":[],\"biases\":[]}\n",
    "    \n",
    "    def init_empty(self,size,n_nodes_hl1,n_nodes_hl2,n_classes):\n",
    "        print(size,n_nodes_hl1,n_nodes_hl2,n_classes)\n",
    "        self.hidden_1_layer = {'weights':tf.Variable(tf.random_normal([size, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "        self.hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "        \n",
    "        self.output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_classes])),\n",
    "                        'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "    def init_values(self,size,l1_weights,l2_weights,l3_weights,out_weights,l1_biases,l2_biases,l3_biases,out_biases):\n",
    "        self.hidden_1_layer = {'weights':tf.Variable(l1_weights),'biases':tf.Variable(l1_biases)}\n",
    "        self.hidden_2_layer = {'weights':tf.Variable(l2_weights),'biases':tf.Variable(l2_biases)}\n",
    "        self.output_layer = {'weights':tf.Variable(out_weights),'biases':tf.Variable(out_biases)}\n",
    "\n",
    "\n",
    "    def create(self,data):\n",
    "        # This is the heart of the ann where multiply the data by the wights to the layers \n",
    "        l1 = tf.add(tf.matmul(data,self.hidden_1_layer['weights']), self.hidden_1_layer['biases'])\n",
    "        l1 = tf.nn.relu(l1)\n",
    "\n",
    "        l2 = tf.add(tf.matmul(l1,self.hidden_2_layer['weights']), self.hidden_2_layer['biases'])\n",
    "        l2 = tf.nn.relu(l2)\n",
    "\n",
    "        \n",
    "        output =  tf.add(tf.matmul(l2,self.output_layer['weights']) , self.output_layer['biases'])\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def extract(self):\n",
    "        self.np_hidden_1_layer[\"weights\"] = neural_network_model.hidden_1_layer[\"weights\"].eval()\n",
    "        self.np_hidden_2_layer[\"weights\"] = neural_network_model.hidden_2_layer[\"weights\"].eval()\n",
    "        self.np_output_layer[\"weights\"] = neural_network_model.output_layer[\"weights\"].eval()\n",
    "        self.np_hidden_1_layer[\"biases\"] = neural_network_model.hidden_1_layer[\"biases\"].eval()\n",
    "        self.np_hidden_2_layer[\"biases\"] = neural_network_model.hidden_2_layer[\"biases\"].eval()\n",
    "        self.np_output_layer[\"biases\"] = neural_network_model.output_layer[\"biases\"].eval()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_interactive(neural_network_model,fold):\n",
    "    x= tf.placeholder('float')\n",
    "    y = tf.placeholder('float')\n",
    "    prediction = neural_network_model.create(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    hm_epochs = 1500\n",
    "    sess = tf.InteractiveSession()\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: train_x[train_index[fold]],\n",
    "                                                          y: train_y[train_index[fold]]})\n",
    "            epoch_loss += c\n",
    "            #if epoch % 100 == 0:\n",
    "            #    print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "    neural_network_model.extract()\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    print('Accuracy:',accuracy.eval({x:train_x[test_index[fold]], y:train_y[test_index[fold]]}))\n",
    "    y_test=(sess.run(prediction,feed_dict={\n",
    "                             x: train_x[test_index[fold]]\n",
    "                              }))       \n",
    "    \n",
    "    true_class=np.argmax(train_y[test_index[fold]],1)\n",
    "    predicted_class=np.argmax(y_test,1)\n",
    "    cm=confusion_matrix(predicted_class,true_class)\n",
    "    pprint(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "train_index=[]\n",
    "test_index=[]\n",
    "splits =10\n",
    "skf = StratifiedKFold(n_splits=splits,random_state=0,shuffle=True)\n",
    "for train_idx, test_idx in skf.split(train_x,train_y[:,0]):               \n",
    "    train_index.append(train_idx)\n",
    "    test_index.append(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 5 5 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/Projects/Python/env/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8666667\n",
      "array([[4, 1, 0],\n",
      "       [1, 5, 0],\n",
      "       [0, 0, 4]])\n",
      "13 5 5 3\n",
      "Accuracy: 0.53333336\n",
      "array([[2, 1, 1],\n",
      "       [3, 6, 2],\n",
      "       [0, 0, 0]])\n",
      "13 5 5 3\n",
      "Accuracy: 0.93333334\n",
      "array([[4, 0, 0],\n",
      "       [1, 3, 0],\n",
      "       [0, 0, 7]])\n",
      "13 5 5 3\n",
      "Accuracy: 0.93333334\n",
      "array([[5, 0, 0],\n",
      "       [0, 5, 1],\n",
      "       [0, 0, 4]])\n",
      "13 5 5 3\n",
      "Accuracy: 0.93333334\n",
      "array([[5, 1, 0],\n",
      "       [0, 6, 0],\n",
      "       [0, 0, 3]])\n",
      "13 5 5 3\n",
      "Accuracy: 1.0\n",
      "array([[5, 0, 0],\n",
      "       [0, 6, 0],\n",
      "       [0, 0, 3]])\n",
      "13 5 5 3\n",
      "Accuracy: 1.0\n",
      "array([[5, 0, 0],\n",
      "       [0, 4, 0],\n",
      "       [0, 0, 5]])\n",
      "13 5 5 3\n",
      "Accuracy: 1.0\n",
      "array([[4, 0, 0],\n",
      "       [0, 6, 0],\n",
      "       [0, 0, 3]])\n",
      "13 5 5 3\n",
      "Accuracy: 0.9230769\n",
      "array([[4, 0, 0],\n",
      "       [0, 6, 0],\n",
      "       [0, 1, 2]])\n",
      "13 5 5 3\n",
      "Accuracy: 0.9230769\n",
      "array([[4, 0, 0],\n",
      "       [0, 6, 1],\n",
      "       [0, 0, 2]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    neural_network_model = TfAnn()\n",
    "    neural_network_model.init_empty(len(train_x[0]),n_nodes_hl1,n_nodes_hl2,n_classes)\n",
    "    train_neural_network_interactive(neural_network_model,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
